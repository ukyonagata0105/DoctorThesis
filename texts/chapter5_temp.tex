\section{ZK-SNARKs模倣システムによる政策対話インフラの構築}\label{zk-snarksux6a21ux5023ux30b7ux30b9ux30c6ux30e0ux306bux3088ux308bux653fux7b56ux5bfeux8a71ux30a4ux30f3ux30d5ux30e9ux306eux69cbux7bc9}

\subsection{市民討議による原則策定とConstitutional AI訓練を統合した政策評価アーキテクチャ}\label{ux5e02ux6c11ux8a0eux8b70ux306bux3088ux308bux539fux5247ux7b56ux5b9aux3068constitutional-aiux8a13ux7df4ux3092ux7d71ux5408ux3057ux305fux653fux7b56ux8a55ux4fa1ux30a2ux30fcux30adux30c6ux30afux30c1ux30e3}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{永田 右京}

岩手県立大学大学院 総合政策研究科 博士後期課程2年

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{要旨}

本研究は、ウィキッド・プロブレム（地球温暖化、少子高齢化等）の政策評価における従来手法の限界を整理し、秘密情報を含む政策提案の実現と専門的判断を両立する新しい枠組みを提案する。本システムの特徴は、市民・研究者による討議を通じてConstitutional AIの憲法的原則を共同策定し、その原則に基づいて訓練されたLarge Language Model（LLM）が政策評価を行う点にある。Zero-Knowledge Succinct Non-interactive Arguments of Knowledge（ZK-SNARKs）の秘匿証明特性を模倣することで、政策提案に含まれる秘密情報を秘匿化処理し、外部に漏らすことなくLLMの評価に使用する。さらに、TEE（Trusted Execution Environment）による分散型評価モデルと、Temperature=0設定およびSelf-Consistency手法による決定論的運用を組み合わせることで、LLMとZK-SNARKsの本質的な違い（数学的保証と確率的期待）に対処し、実用上の信頼性を高める工学的アプローチを提案する。このアーキテクチャにより、市民参加による民主的正当性の確保、秘密情報を含む具体的な政策提案の実現、専門的視点に基づく評価、人間による最終的な評価決定の保障を同時に達成することを目指す。

\textbf{キーワード}: ウィキッド・プロブレム、ZK-SNARKs、Constitutional AI、LLM as a Judge、TEE（Trusted Execution Environment）、政策評価、市民討議、秘密情報の秘匿化

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{1. はじめに}\label{ux306fux3058ux3081ux306b}

\subsubsection{1.1 研究の背景}\label{ux7814ux7a76ux306eux80ccux666f}

現代社会が直面するウィキッド・プロブレム（Wicked Problems）は、その複雑性と多面性により、従来の政策立案・評価手法では適切に対処することが困難である。Rittel and Webber（1973）が提唱したこの概念は、明確な解が存在せず、多様なステークホルダーの価値観が対立し、試行錯誤による学習が不可欠な問題群を指す。地球温暖化、少子高齢化、都市計画、医療政策といった現代的課題は、いずれもこの特徴を備えており、単一の専門分野や手法では解決が困難である。

ウィキッド・プロブレムの政策評価においては、多様な専門知識の統合が不可欠である。しかしながら、企業の技術情報、研究機関の未公開データ、個人の経験知など、政策評価に有用な情報の多くは秘匿性を要求される。従来の政策評価プロセスでは、こうした機密情報の提供を前提とするため、情報提供者の参加が制限され、評価の質と正当性が損なわれてきた。この構造的矛盾により、専門性の高い評価と参加者の秘匿性保護の両立が、政策対話における本質的課題となっている。

\subsubsection{1.2 従来手法の限界}\label{ux5f93ux6765ux624bux6cd5ux306eux9650ux754c}

政策評価の手法は、その目的や志向性によって多様であり、杉谷（2019）によれば、デモクラシーの類型に対応した複数の評価タイプが存在する。しかし、いずれのタイプにも固有の限界がある。

第一に、プロフェッショナル評価（専門家主導型）の限界がある。この方式では、評価の専門家や行政職員が実務を進め、市民はアンケートや情報源として扱われる。専門家の知見を活用できる一方で、テクノクラシー（専門家支配）に偏向する可能性が指摘されている（杉谷, 2019, p.190）。政治エリートの能力や意欲に依存し、民主的性格を失う恐れがある。また、専門家が保有する機密情報を評価に反映させることができず、評価の質が制限される。

第二に、ステークホルダー評価（利害関係者参加型）の限界がある。この方式では、政策に利害関係を持つ者（受益者、管理者、専門家など）が評価プロセスに参加し、多元的な視点を反映させることを目的とする。しかし、利害関係者間の利害対立を解決する方法がない場合、評価自体が紛争の場になりかねない（杉谷, 2019, p.198）。

第三に、協働型評価（専門家＋市民）の限界がある。この方式では、評価担当者がファシリテーターの役割を担い、関係者と協力してプログラム理論の構築や評価を行う。しかし、機密情報の取り扱いが困難であり、専門知と市民参加の質的両立が難しいという課題が残る。

さらに、EBPM（エビデンスに基づく政策形成）の文脈では、「説明責任（Accountability）」と「応答責任（Responsiveness）」の間に緊張関係が存在する（窪田・山谷編, 2020, p.213）。説明責任は近代科学的エビデンス（普遍性を志向）に基づき外部の第三者による統制を可能にするのに対し、応答責任は現場の実践家が個別ニーズや生活世界に根差したエビデンスに基づき果たすべき責任である。アーギロス（Argyrous, 2012）が指摘するように、EBPMにおける透明性は、行政を一方的に監視するためだけでなく、エビデンスの導出プロセスをオープンにすることでエビデンスの多元性を確保することに資する（杉谷, 2019, p.229）。

これらの限界は、秘匿性と透明性、専門性と参加性、説明責任と応答責任という相反する要求を同時に満たすことの困難さに起因する。奥田（2019）らが指摘するように、ウィキッド・プロブレムの解決には「ステークホルダーの合意調達と、柔軟かつ迅速な専門知・実践知の調達・適用」の連動が不可欠であるが、従来の枠組みではこの連動を実現する技術的基盤が欠如していた。

\subsubsection{1.3 本研究の目的}\label{ux672cux7814ux7a76ux306eux76eeux7684}

本研究の目的は、市民討議による原則策定、ZK-SNARKsによる秘密情報の秘匿化処理、Constitutional AI訓練手法による専門的価値観の埋め込みを統合した政策対話インフラを構築することである。このシステムにより、以下の4つの目標を達成する。

第一に、市民参加による民主的正当性と専門的評価の両立を実現する。本システムの特徴的な点は、Constitutional AIの憲法的原則を市民・研究者の討議を通じて共同策定することにある。自治体が討議を運営・記録し、市民と研究者が対話を通じて「公平性」「透明性」「プライバシー保護」などの原則を定義する。この過程により、LLMの訓練基盤となる原則に民主的正当性が付与される。討議で策定された原則に基づいてConstitutional AI訓練を行うことで、市民の価値観を反映した専門的判断が可能となる。

第二に、秘密情報を含む政策提案の実現を可能にする。ZK-SNARKsの秘匿証明特性を模倣することで、政策提案者は企業秘密や未公開研究データをシステムに提出できる。秘密情報は外部に一切漏らさず、LLMの評価にのみ使用される。これにより、企業の技術情報や研究機関の未公開データを含む具体的根拠を持つ政策提案が可能となりながら、知的財産や競争優位性を保護することができる。

第三に、参加者の多様化と提案の質的向上を実現する。秘匿性の保証により、従来参加を躊躇していた研究機関が具体的な技術データや研究成果を含む高品質な政策提案を提出できる。市民は意見を提出し、研究者は機密データを含む提案を行う。専門的価値観に基づく評価により、提案内容そのもので判断され、権威や社会的地位に依存しない公平な評価システムを構築する。

第四に、透明性と秘密保護の両立を強化する。ZK-SNARKsにより、提案の計算結果が秘密データに基づいて正しく導出されたことを証明しつつ、評価プロセスの透明性を保ちながら提案に含まれる秘密情報を保護する。自治体・行政が最終判断を行い、議会・住民への説明責任を果たす。これにより、行政の説明責任を技術的に保証し、市民の信頼を獲得する。

本論文の構成は以下の通りである。第2章では、ZK-SNARKsの技術的基礎とその政策評価への適用可能性を検討する。第3章では、Constitutional AIとLLM as a Judgeの技術的特性を整理し、政策評価における役割を明らかにする。第4章では、提案するシステムアーキテクチャを詳述し、技術統合の方法論を示す。第5章では、期待される効果と今後の展望を論じる。

\pandocbounded{\includesvg[keepaspectratio]{research-overview.svg}}
\emph{図1：本研究の全体像 - 市民討議、ZK-SNARKs、Constitutional AIの統合アーキテクチャ}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{2. ZK-SNARKsと秘匿証明}\label{zk-snarksux3068ux79d8ux533fux8a3cux660e}

\subsubsection{2.1 ZK-SNARKsの技術的基礎}\label{zk-snarksux306eux6280ux8853ux7684ux57faux790e}

Zero-Knowledge Succinct Non-interactive Arguments of Knowledge（ZK-SNARKs）は、暗号学における秘匿証明プロトコルであり、4つの本質的特性を持つ。これらの特性により、従来は不可能であった「秘密を完全に守りながら、その秘密に関する知識を持っていることを証明する」ことが技術的に実現可能となった。

Zero-Knowledge（ゼロ知識）特性は、証明を通して元の秘密情報が一切漏洩しないことを保証する。検証者は「証明者が知識を持っている」という事実のみを確認でき、知識そのものは一切得られない。この特性により、機密情報の詳細を開示することなく、その情報の保持を証明することが可能となる。

Succinct（簡潔）特性は、どんなに複雑な計算であっても証明サイズが常に数百バイト程度と一定であることを意味する。膨大なデータの正しさを小さな証明で検証可能であり、計算効率と通信効率の両面で優れた性能を発揮する。この特性により、大規模な政策評価プロセスにおいても実用的な処理時間で証明の生成と検証が可能となる。

Non-interactive（非対話）特性は、証明者から検証者への1回の送信で証明が完了することを示す。複数回のやり取りを必要とせず、オンライン通信の負荷を大幅に削減する。この特性により、非同期的な政策評価プロセスや、多数の参加者が関与する大規模な協議においても効率的な運用が可能となる。

Arguments of Knowledge（知識の論証）特性は、証明者が本当にその知識を所有している必要があり、偽造が計算量的に不可能であることを保証する。数学的安全性により信頼性が確保され、悪意のある参加者による不正な証明の作成を防止する。

これらの4つの特性は、楕円曲線暗号などの数学的基盤により実現される。特に、楕円曲線上の離散対数問題の計算困難性に基づくペアリング演算を利用することで、効率的な証明生成と検証が可能となる。Groth（2016）により提案されたGroth16方式は、現在最も効率的なZK-SNARKs実装の一つであり、証明サイズが128バイト、検証時間が数ミリ秒という実用的な性能を達成している。

\pandocbounded{\includesvg[keepaspectratio]{zk-snarks-properties.svg}}
\emph{図2：ZK-SNARKsの4つの特性 - Zero-Knowledge、Succinct、Non-interactive、Arguments of Knowledge}

\subsubsection{2.2 政策提案への適用可能性}\label{ux653fux7b56ux63d0ux6848ux3078ux306eux9069ux7528ux53efux80fdux6027}

ZK-SNARKsの秘匿証明特性は、政策提案における秘密情報保護と提案の具体性の両立という構造的課題に対する技術的解決策を提供する。従来、参加者が保有する機密情報を政策提案に含めるためには、その情報の詳細を開示する必要があり、これが具体的な提案の提出を阻害してきた。ZK-SNARKsを用いることで、提案者は機密情報そのものを開示することなく、その情報を含む政策提案をシステムに提出できる。

具体的には、提案者が保有する技術データ、研究成果、実証実験の結果などを秘密情報として扱い、これらの情報を含む政策提案をシステムに提出する。ZK-SNARKsの秘匿化処理により、秘密情報はLLMの評価に使用されるが、外部には一切漏らさない。証明プロセスにより、提案に含まれる計算結果（例：「CO2を30\%削減できる」）が実際に秘密情報に基づいて正しく導出されたことを、秘密情報を開示することなく証明できる。検証者は、証明を検証することで、提案の計算結果が秘密データに基づいて正しいことを確認できるが、秘密データの詳細にはアクセスできない。

この仕組みにより、企業は競争優位性を損なうことなく具体的な技術データを含む政策提案を提出でき、研究機関は未公開の研究成果を保護しながら科学的根拠を含む提案を行うことができる。また、個人は経験知やノウハウといった暗黙知を秘匿しながら、その知見に基づく提案を行うことができる。この結果、従来は抽象的な提案しかできなかった多様なステークホルダーが、具体的根拠を持つ高品質な政策提案を提出することが可能となり、政策の質と実効性が向上する。

\pandocbounded{\includesvg[keepaspectratio]{zk-snarks-concept.svg}}
\emph{図3：ZK-SNARKsによる秘匿証明の概念 - 秘密情報を開示せずに知識を証明}

さらに、ZK-SNARKsの非対話特性により、評価者は自身の都合の良いタイミングで証明を生成し、非同期的に提出できる。これにより、時間的・空間的制約を受けずに大規模な参加型評価を実現できる。Succinct特性により、証明サイズが小さく保たれるため、ネットワーク帯域や保存容量の制約も最小限に抑えられる。

\subsubsection{2.3 ZK-SNARKs vs STARKs：文脈依存性の必然}\label{zk-snarks-vs-starksux6587ux8108ux4f9dux5b58ux6027ux306eux5fc5ux7136}

ZK-SNARKsの代替技術としてZK-STARKs（Scalable Transparent Arguments of Knowledge）が存在するが、本研究では政策評価の文脈においてZK-SNARKsが適していると判断した。この選択の理論的根拠は、政策評価における文脈依存性の本質にある。

STARKsの根本的特徴は、Trusted Setupを必要としないUniversal性にある。これは、どんな文脈でも同じアルゴリズムを適用し、数学的に一律な検証基準を用いることを意味する。この特性は、暗号通貨のような文脈に依存しない純粋な計算検証には適しているが、政策評価という本質的に文脈依存的な領域には適合しない。

政策評価の現実は、文脈依存性が本質である。地域、時代、文化によって評価基準が変化し、人間の規範が動的に創造される。ステークホルダーは異なる価値体系を持ち、これらの多様性を尊重しながら合意形成を図る必要がある。STARKsのUniversal性は、この文脈依存的な評価を適切に扱うことができない。

対照的に、ZK-SNARKsのTrusted Setupは、文脈に応じたカスタマイズされた評価システムの構築を可能にする。各政策分野、各地域、各時代に応じて最適化された証明システムを設計できる。Trusted Setupの過程で、その文脈における重要な価値観や評価基準を反映させることができる。この柔軟性により、政策評価の文脈依存的な性質に適合したシステムを構築できる。

さらに、ZK-SNARKsは証明サイズと検証時間において優れた性能を示す。Groth16方式では証明サイズが128バイトと極めて小さく、検証時間も数ミリ秒と高速である。大規模な参加型政策評価において、多数の証明を効率的に処理する必要がある場合、この性能差は実用上重要な意味を持つ。

ただし、Trusted Setupのプロセスには慎重な設計が必要である。複数の独立した参加者によるマルチパーティ計算（MPC）を用いることで、単一の参加者が秘密鍵を保持するリスクを排除できる。実際に、Zcashプロジェクトでは2016年のSprout ceremony（6人）から2018年のSapling ceremony（90人）へと参加者を拡大し、Tornado.cashはブラウザベースの参加を可能にすることで1,114人の参加者を集めた（Buterin, 2022）。さらに、2023年に開始されたEthereum KZG Ceremonyは約95,000件の貢献を集め、史上最大規模のTrusted Setup ceremonyとなった（Ethereum Foundation, 2023）。これらの実績により、実用上の安全性は十分に確保できることが示されている。

\pandocbounded{\includesvg[keepaspectratio]{snarks-vs-starks.svg}}
\emph{図4：ZK-SNARKsとSTARKsの比較 - 文脈依存性と性能特性}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{3. Constitutional AIとLLM as a Judge}\label{constitutional-aiux3068llm-as-a-judge}

\subsubsection{3.1 LLM as a Judgeの概念と発展}\label{llm-as-a-judgeux306eux6982ux5ff5ux3068ux767aux5c55}

Large Language Modelを評価者（Judge）として活用するLLM as a Judgeの概念は、2024年以降急速に発展した研究領域である。従来、テキスト生成や質問応答などのタスクにおけるLLMの性能評価は、人間による主観的判断や、BLEUスコアなどの自動評価指標に依存していた。しかし、これらの手法は評価の一貫性、スケーラビリティ、コスト効率の面で課題を抱えていた。

LLM as a Judgeは、LLM自身が他のLLMの出力や人間の文章を評価する枠組みである。この手法の理論的基盤は、大規模言語モデルが訓練過程で獲得した広範な知識と、人間の価値判断パターンの学習にある。Shi et al.（2024）による包括的調査によれば、LLM as a Judgeは単純な品質評価から、論理的整合性、事実正確性、倫理的適切性など、多次元的な評価が可能である。

Wang et al.（2024-2025）は、LLMベースの評価手法を体系的に整理し、その有効性を実証した。特に、Chain-of-Thought（CoT）推論を組み込むことで、評価プロセスの透明性が向上し、評価根拠の説明が可能となることを示した。Gu et al.（2025）は、開放型対話システムの評価におけるLLM as a Judgeの有効性を検証し、人間評価者との高い一致率を報告している。

政策評価への応用という観点では、LLM as a Judgeは以下の特性により有用である。第一に、大量の政策提案を効率的に処理できる。人間の評価者では処理しきれない規模の提案に対しても、一貫した基準で迅速な評価が可能である。第二に、多様な視点からの評価を統合できる。複数の評価基準を同時に考慮し、それらのバランスを取りながら総合的な判断を行う。第三に、評価プロセスの透明性を確保できる。評価理由を自然言語で説明することで、評価結果の解釈可能性が向上する。

\pandocbounded{\includesvg[keepaspectratio]{llm-judge-concept.svg}}
\emph{図5：LLM as a Judgeの概念 - 政策提案の多基準評価と説明生成}

\subsubsection{3.2 LLM as a Judgeの限界と課題}\label{llm-as-a-judgeux306eux9650ux754cux3068ux8ab2ux984c}

LLM as a Judgeは有用な評価手法である一方で、いくつかの重要な限界を持つ。これらの限界を理解し、適切に対処することが、実用的な政策評価システムの構築には不可欠である。

第一の限界は、幻覚（Hallucination）問題である。LLMは、訓練データに含まれない情報や、事実と異なる内容を、もっともらしく生成する傾向がある。政策評価においては、根拠のない評価や、誤った事実認識に基づく判断が重大な問題となる。特に、専門的な技術事項や最新の研究成果に関する評価では、LLMの知識の限界が顕在化する。

第二の限界は、バイアスと公平性の問題である。LLMは訓練データに含まれる社会的バイアスを学習し、それが評価に反映される可能性がある。性別、人種、地域、社会階層などに関する潜在的な偏見が、政策評価の公平性を損なう恐れがある。さらに、訓練データの分布により、特定の政治的立場や価値観に偏った評価を行う可能性も指摘されている。

第三の限界は、文脈理解の不完全性である。ウィキッド・プロブレムのような複雑な政策課題では、多層的な文脈理解が必要となるが、現在のLLMはこの能力に限界がある。特に、地域固有の事情、歴史的経緯、文化的背景などの深い理解が要求される場合、LLMの評価は表面的になる可能性がある。

第四の限界は、説明責任と最終決定権の問題である。LLMによる評価は確率的な推論に基づいており、その判断過程は完全には解明されていない。政策評価という公共性の高い領域において、アルゴリズムによる自動的な決定に全面的に依存することは、民主的正当性と説明責任の観点から問題がある。

これらの限界に対処するため、本研究ではConstitutional AI訓練手法を導入し、さらに人間による最終的な評価決定を保障するシステム設計を採用する。

\subsubsection{3.3 Constitutional AI：訓練手法の理論的基礎}\label{constitutional-aiux8a13ux7df4ux624bux6cd5ux306eux7406ux8ad6ux7684ux57faux790e}

Constitutional AI（憲法的AI）は、Anthropicにより2022年に提案された、LLMを人間の価値観に整合させる訓練手法である。Bai et al.（2022）による原著論文では、人間が定義した憲法的原則（Constitution）に基づいてAI自身が自己改善を行う手法が提示されている。

Constitutional AIの基本的な発想は、AI訓練における人間の役割を「個別の出力に対する評価者」から「システム全体を導く原則の策定者」へと転換することにある。従来のReinforcement Learning from Human Feedback（RLHF）では、人間は個々のAI出力に対して「良い」「悪い」の判断を下す必要があり、これが大きな労力とコストを要した。Constitutional AIでは、人間は「helpful（有用である）」「harmless（無害である）」「honest（誠実である）」といった高次の原則を自然言語で定義し、AIがこれらの原則に基づいて自己評価と自己修正を行う。

訓練プロセスは2つのフェーズから構成される。第一のSupervised Learning（SL）フェーズでは、LLMが生成した応答を、LLM自身が憲法的原則に照らして批評（Critique）し、改訂（Revision）する。この自己批評と自己修正のプロセスを繰り返すことで、LLMは憲法的原則を内在化していく。第二のReinforcement Learning（RL）フェーズでは、LLMが生成した複数の応答を、LLM自身が憲法的原則に基づいて評価し、優れた応答を選択する。この評価を用いてPreference Model（選好モデル）を訓練し、さらにこのモデルを報酬信号として強化学習を行う。このプロセスは「Reinforcement Learning from AI Feedback（RLAIF）」と呼ばれる。

Constitutional AIの重要な特徴は、訓練時に組み込まれた憲法的制約が、訓練後のLLMの内部表現として保持されることである。これにより、運用時には外部からの継続的な監視や介入なしに、LLMが自律的に倫理的制約を遵守した判断を行うことができる。この特性は、ZK-SNARKsにおける楕円曲線暗号の役割と類似している。楕円曲線暗号がZK-SNARKsの数学的安全性を基盤として保証するように、Constitutional AIはLLMの倫理的信頼性を基盤として保証する。

政策評価への応用という観点では、Constitutional AIは以下の利点を提供する。第一に、公平性、透明性、プライバシー保護といった政策評価に必要な倫理的原則を、訓練時に明示的に組み込むことができる。第二に、市民討議という民主的プロセスで合意された判断基準をLLMに内在化させることで、評価基準に民主的正当性を付与できる。第三に、評価理由の説明において、憲法的原則への言及を通じて、評価の透明性と説明責任を向上させることができる。

\pandocbounded{\includesvg[keepaspectratio]{constitutional-ai-process.svg}}
\emph{図6：Constitutional AIの訓練プロセス - 市民討議による原則策定からLLM as a Judgeへ}

\subsubsection{3.4 Constitutional AI訓練によるLLM as a Judgeの実現}\label{constitutional-aiux8a13ux7df4ux306bux3088ux308bllm-as-a-judgeux306eux5b9fux73fe}

本研究では、Constitutional AI訓練手法により訓練されたLLMを、LLM as a Judgeとして政策評価に活用する。この統合的アプローチにより、LLM as a Judgeの限界を克服し、信頼性の高い政策評価支援システムを実現する。

訓練プロセスにおいて、政策評価に特化した憲法的原則と専門的価値観を定義する。憲法的原則には、公平性（特定の集団やイデオロギーへの偏向を避ける）、透明性（評価理由を明確に説明する）、プライバシー保護（個人情報や機密情報を適切に扱う）、科学的根拠の重視（エビデンスに基づく評価を行う）、多様な視点の尊重（異なる価値観を認識し考慮する）などが含まれる。専門的価値観には、各政策分野（環境、福祉、都市計画等）における専門家の判断パターン、評価基準、重視すべき要素などが含まれる。

SLフェーズでは、様々な政策提案に対する評価を生成し、それを憲法的原則と専門的価値観に照らして自己批評する。例えば、「この評価は特定の政治的立場に偏っていないか」「評価理由は十分に明確か」「科学的根拠は適切に引用されているか」「専門的観点から適切な判断基準を用いているか」といった観点から、AI自身が評価を見直し、改善する。この反復的プロセスにより、政策評価に適した判断パターンと専門的視点が学習される。

RLフェーズでは、複数の評価候補を生成し、それらを憲法的原則と専門的価値観に基づいて比較評価する。専門家の判断パターンを訓練データとして学習し、AI評価（RLAIF）を報酬信号として強化学習を行う。Chain-of-Thought推論を組み込むことで、「なぜこの評価がより公平か」「どの評価がより専門的観点から適切か」といった判断プロセスを明示化する。これにより、最終的な評価選択の根拠が明確化され、説明可能性が向上する。

訓練されたLLM as a Judgeは、政策評価において以下の機能を提供する。第一に、大量の政策提案を効率的に処理し、初期スクリーニングや優先順位付けを行う。第二に、訓練された専門的価値観に基づいて評価を実行する。第三に、評価理由を自然言語で説明し、評価の透明性を確保する。第四に、憲法的制約と専門的判断基準に基づく自律的な判断により、一貫性のある公平な評価を提供する。

重要な点として、LLM as a Judgeは最終的な決定を行うのではなく、人間による意思決定を支援する役割に徹する。Constitutional AI訓練により、「アルゴリズムは支援に徹し、最終決定は人間が実施する」という原則が内在化されている。これにより、民主的正当性と説明責任を確保しながら、AIの効率性と専門的判断能力を活用することが可能となる。

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{4. システムアーキテクチャと技術統合}\label{ux30b7ux30b9ux30c6ux30e0ux30a2ux30fcux30adux30c6ux30afux30c1ux30e3ux3068ux6280ux8853ux7d71ux5408}

\subsubsection{4.1 全体アーキテクチャの概要}\label{ux5168ux4f53ux30a2ux30fcux30adux30c6ux30afux30c1ux30e3ux306eux6982ux8981}

本研究が提案する政策対話インフラは、Constitutional AI訓練手法により訓練されたLLM as a Judgeを中核とし、ZK-SNARKsの秘匿証明特性を統合したシステムである。このアーキテクチャは、人間、訓練プロセス、運用システムという3つの層から構成される。

人間層では、政策評価に関わる全てのステークホルダーが参加する。この層の主要な役割は四つある。第一に、市民と研究者が討議を通じてConstitutional AIの憲法的原則を共同策定することである。自治体が討議を運営・記録し、市民と研究者が対話を通じて「公平性」「透明性」「プライバシー保護」「科学的根拠の重視」などの原則を定義する。この討議プロセスにより、LLMの訓練基盤となる原則に民主的正当性が付与される。第二に、各政策分野の専門的価値観を定義することである。研究者が環境政策、福祉政策、都市計画など、分野ごとの専門家の判断パターンや評価基準を整理する。第三に、政策提案を提出することである。市民は意見を提出し、研究者は機密データを含む提案を行う。第四に、最終的な評価決定を行うことである。自治体・行政がLLM as a Judgeによる評価結果を参考にしながら最終判断を行い、議会・住民への説明責任を果たす。

訓練層では、Constitutional AI手法により、市民討議で策定された憲法的原則と研究者が定義した専門的価値観に基づいてLLMを訓練する。SLフェーズにおいて、AI自身が政策評価の応答を生成し、市民が定めた憲法的原則と専門的価値観に照らして自己批評と自己修正を繰り返す。RLフェーズにおいて、専門家の判断パターンを学習し、AI評価（RLAIF）を報酬信号として強化学習を行い、民主的に策定された憲法的制約と専門的判断基準をLLMの内部表現として内在化させる。この訓練プロセスにより、市民の価値観と専門的視点を組み込んだLLMが生成される。

運用層では、訓練されたLLM as a Judgeが政策評価を実行する。このLLMは、ZK-SNARKsの秘匿証明特性と政策評価システムを単一のトランスフォーマーモデル内で統合的に実装する。具体的には、LLMは秘密情報を含む政策提案を入力として受け取り、訓練された専門的価値観に基づく評価を実行し、出力層において秘密を含まない評価結果と評価の根拠・理由を出力する。評価結果は自然言語で説明される。

このアーキテクチャの特徴は、市民討議による原則策定、Constitutional AI訓練、LLM as a Judgeによる運用という一貫したフローにある。市民と研究者が討議を通じて定めた原則がConstitutional AI訓練の基盤となり、その訓練によりLLMに内在化された倫理的制約と専門的判断基準が運用時の自律的判断を導く。外部からの継続的な監視や介入を必要とせず、民主的に策定された原則に基づいてLLMが評価を行う。この仕組みは、楕円曲線暗号がZK-SNARKsの数学的安全性を基盤として保証するように、市民討議とConstitutional AIがLLMの民主的正当性と専門性を基盤として保証することに類似している。

\pandocbounded{\includesvg[keepaspectratio]{integration-architecture.svg}}
\emph{図7：提案するシステムの統合アーキテクチャ - 人間層、訓練層、運用層の構成}

\subsubsection{4.2 ZK-SNARKs秘匿証明特性のLLM実装：秘密情報の秘匿化処理}\label{zk-snarksux79d8ux533fux8a3cux660eux7279ux6027ux306ellmux5b9fux88c5ux79d8ux5bc6ux60c5ux5831ux306eux79d8ux533fux5316ux51e6ux7406}

LLMトランスフォーマーモデルにおけるZK-SNARKs秘匿証明特性の実装は、本研究の技術的核心の一つである。この実装により、政策提案に含まれる秘密情報を秘匿化処理し、LLMの評価に使用するが外部には一切漏らさない。

実装の第一段階は、政策提案に含まれる秘密情報の入力処理である。提案者が提出する技術データ、研究成果、実証実験の結果などの機密情報を、LLMは入力として受け取る。重要な点は、LLMは秘密情報を「見ている」ということである。秘密情報をベクトル空間に埋め込んで隠蔽するのではなく、LLMは入力された秘密情報の内容を処理する。

第二段階は、専門的価値観に基づく提案の評価実行である。LLMの内部処理において、Constitutional AI訓練により内在化された専門的価値観に基づいて、秘密情報を含む政策提案を評価する。Transformer architectureのAttention機構により、入力情報と訓練された専門的判断基準を統合し、提案の妥当性を判断する。

第三段階は、評価結果の出力である。LLMの出力層において、秘密情報を含まない政策評価結果を生成する。同時に、評価の根拠・理由を生成し、どのような観点から評価が行われたかを説明する。重要な特性は、出力される評価結果と根拠がいずれも秘密情報を含まないことである。検証者は、評価結果と根拠を確認できるが、秘密データの詳細にはアクセスできない。

この実装により、ZK-SNARKsの4つの特性をLLM上で模倣することを目指す。Zero-Knowledge特性は、出力時に秘密情報を含めないことにより模倣される。Succinct特性は、評価結果のサイズが入力情報のサイズに依存せず簡潔であることにより模倣される。Non-interactive特性は、評価者が一度の出力で評価を完結できることにより模倣される。Arguments of Knowledge特性は、LLMの訓練過程において学習された知識表現の整合性により模倣される。

\textbf{ただし、LLMによる実装は、真のZK-SNARKsとは本質的に異なる点に留意が必要である。} ZK-SNARKsは楕円曲線暗号に基づき、秘密が漏れないことを数学的に保証する。一方、LLMは秘密情報を入力として受け取り、出力時に秘密を含めないように訓練されているだけであり、秘密が漏れないことの確率的な期待しか持てない。敵対的なプロンプトにより秘密を漏洩させられるリスクが残る。この本質的な違いを認識した上で、次節で述べる工学的アプローチにより、実用上の信頼性を高める方策を検討する。

\subsubsection{4.3 秘匿性と再現性を高める工学的アプローチ}\label{ux79d8ux533fux6027ux3068ux518dux73feux6027ux3092ux9ad8ux3081ux308bux5de5ux5b66ux7684ux30a2ux30d7ux30edux30fcux30c1}

前節で述べたLLMとZK-SNARKsの本質的な違いに対処するため、本研究では2つの工学的アプローチを提案する。これらは数学的保証には及ばないものの、実用上の信頼性を高められる可能性がある。

\paragraph{4.3.1 TEE（Trusted Execution Environment）による分散型評価モデル}\label{teetrusted-execution-environmentux306bux3088ux308bux5206ux6563ux578bux8a55ux4fa1ux30e2ux30c7ux30eb}

第一のアプローチは、TEE（Trusted Execution Environment：信頼できる実行環境）を活用した分散型評価システムである。TEEとは、Intel SGXやAWS Nitro Enclavesなどに代表される、ハードウェアレベルで隔離された実行環境を指す。

このアプローチでは、Constitutional AI訓練により構築された評価用LLMを、Dockerコンテナなどの形式でパッケージ化し、各事業者（政策提案者）に配布する。事業者は、自身のローカル環境に設置されたTEE内でこのモデルを実行し、秘密情報を含む政策提案を入力として評価を行う。

TEEの重要な特性は、Remote Attestation（遠隔証明）機能である。これにより、「配布されたプログラムが改ざんされずに実行された」ことを電子署名によって証明できる。事業者は評価結果とこの証明書のみを行政側に送信し、秘密データそのものは事業者のローカル環境から外に出ることがない。

この構成は、ZK-SNARKsにおける証明者（Prover）と検証者（Verifier）の関係に類似している。ZK-SNARKsでは、証明者がローカルで証明を生成し、検証者は証明のみを受け取って検証する。本提案では、事業者がTEE内で評価を実行し、行政側は評価結果とTEEの証明書を受け取って検証する。秘密データが外部に送信されない点で、実用的な秘匿性の担保が期待できる。

ただし、TEEにも限界がある。サイドチャネル攻撃などの脆弱性が報告されており、完全な秘匿性を保証するものではない。また、TEE環境の構築コストや、モデル配布のインフラ整備といった実務的な課題も存在する。

\paragraph{4.3.2 決定論的運用による再現性の確保}\label{ux6c7aux5b9aux8ad6ux7684ux904bux7528ux306bux3088ux308bux518dux73feux6027ux306eux78baux4fdd}

第二のアプローチは、LLMの確率的な挙動を抑制し、再現性を高める運用手法である。LLMは本質的に確率的なモデルであり、同じ入力に対しても異なる出力を生成する可能性がある。これは、行政手続きに求められる「いつ誰がやっても同じ結果になる」という公平性・一貫性の要件と相容れない。

この課題に対処するため、2つの手法を組み合わせる。第一に、Temperature（温度）パラメータを0に設定する。Temperatureは、LLMの出力分布のエントロピーを制御するパラメータであり、0に設定することで、最も確率の高いトークンのみを選択する決定論的な出力が得られる。これにより、同じ入力に対して常に同じ出力を生成することが期待できる。

第二に、Self-Consistency（自己無撞着性）手法を適用する。これは、同じ評価を複数回実行し、結果を集約する手法である。数値評価の場合は平均値を採用することで外れ値を排除し、文章評価の場合は多数決により最頻出の結論を採用する。この手法により、ハルシネーション（幻覚）のリスクを統計的に低減できる可能性がある。

これらの手法を組み合わせることで、LLMの確率的な揺らぎを抑制し、行政手続きに求められる再現性と一貫性を高められる可能性がある。ただし、これらはあくまで工学的なアプローチであり、ZK-SNARKsのような数学的保証を提供するものではない。実際に行政手続きの要件を満たせるかどうかは、今後の実証実験による検証が必要である。

\subsubsection{4.4 システムの運用フロー}\label{ux30b7ux30b9ux30c6ux30e0ux306eux904bux7528ux30d5ux30edux30fc}

提案するシステムの運用フローは、準備段階、評価段階、決定段階の3つのフェーズから構成される。

準備段階では、市民討議による原則策定と評価基準の設定を行う。まず、自治体が討議を運営し、対象となるウィキッド・プロブレムを明確化する。次に、市民と研究者が対話を通じてConstitutional AIの憲法的原則を共同策定する。この討議プロセスにより、「公平性」「透明性」「プライバシー保護」などの原則に民主的正当性が付与される。策定された原則に基づいてConstitutional AI訓練を行い、LLM as a Judgeを構築する。

評価段階では、政策提案の収集と評価の実行を行う。市民は意見を提出し、研究者は機密データを含む提案を行う。この際、ZK-SNARKs秘匿証明特性をLLMで実装したシステムを用いることで、研究者は機密情報を開示することなく具体的根拠を持つ提案を提出できる。LLM as a Judgeは、各政策提案について、市民討議で策定された原則と専門的価値観に基づいて多面的な評価を実行し、評価結果と評価の根拠・理由を生成する。

決定段階では、評価結果の確認と最終決定を行う。まず、LLM as a Judgeによる評価結果と根拠を確認し、評価の妥当性を検討する。次に、評価結果を自治体・行政の意思決定者に提示する。この際、評価理由と根拠が自然言語で説明され、透明性が確保される。最終的な政策決定は、自治体・行政がこれらの情報を参考にしながら行い、議会・住民への説明責任を果たす。Constitutional AI訓練により、LLMは「アルゴリズムは支援に徹し、最終決定は人間が実施する」という原則を遵守している。

このフローにより、市民参加による民主的正当性の確保、秘密情報を含む政策提案の実現、専門的価値観に基づく評価、自治体・行政による説明責任の強化という4つの目標が達成される。

\pandocbounded{\includesvg[keepaspectratio]{stakeholder-journey.svg}}
\emph{図8：政策対話インフラにおけるステークホルダージャーニー - 市民、研究者、自治体の協働プロセス}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{5. 期待される効果と今後の展望}\label{ux671fux5f85ux3055ux308cux308bux52b9ux679cux3068ux4ecaux5f8cux306eux5c55ux671b}

\subsubsection{5.1 期待される効果}\label{ux671fux5f85ux3055ux308cux308bux52b9ux679c}

本研究が提案する政策対話インフラは、ウィキッド・プロブレムの政策評価において、以下の4つの効果をもたらすことが期待される。

第一の効果は、市民参加による民主的正当性と専門的評価の両立である。市民と研究者が討議を通じてConstitutional AIの憲法的原則を共同策定することで、LLMの訓練基盤に民主的正当性が付与される。自治体が討議を運営・記録することで、プロセスの透明性が確保される。ZK-SNARKsにより、研究機関の未公開データを含む具体的な政策提案をシステムに提出できる。秘密情報は外部に一切漏らさず、LLMの評価にのみ使用される。市民討議で策定された原則とConstitutional AI訓練により専門的価値観を埋め込んだLLMが、秘密情報を含む提案を市民の価値観と専門的視点の両方から評価する。この結果、民主的正当性を持つ高品質な政策評価が実現し、自治体・行政の説明責任が強化される。

第二の効果は、多様な提案の包摂と公平な評価の実現である。ウィキッド・プロブレムは、異なる価値観を持つ多様なステークホルダーが関与する問題である。市民討議で策定された憲法的原則に基づいてConstitutional AI訓練を行うことで、民主的プロセスによって合意された判断基準をLLMに内在化させたLLM as a Judgeが実現される。秘匿性の保証により、研究機関が具体的な技術データや研究成果を含む提案を提出できる。市民は意見を提出し、研究者は機密データを含む提案を行う。提案内容そのもので判断されるため、権威や社会的地位に依存しない公平な評価が実現される。

第三の効果は、市民の価値観と専門的判断の調和である。市民討議で策定された原則がConstitutional AI訓練の基盤となることで、市民の価値観がLLMの判断に反映される。同時に、「アルゴリズムは支援に徹し、最終決定は人間が実施する」という原則がLLMに内在化されている。これにより、LLM as a Judgeは市民の価値観と専門的価値観の両方に基づいて大量の政策提案を効率的に処理し、初期スクリーニングや優先順位付けを行うが、最終的な決定は自治体・行政が担う。この仕組みにより、AIの効率性を活用しながら、民主的正当性と説明責任を確保できる。

第四の効果は、政策対話の質的向上と社会的信頼の獲得である。市民討議による原則策定プロセスにより、市民が政策評価の基盤に直接参加する機会が創出される。評価理由の自然言語説明により、評価プロセスの透明性が確保され、市民の理解が促進される。ZK-SNARKsにより、提案の計算結果が秘密データに基づいて正しく導出されたことが証明され、自治体・行政の説明責任が技術的に保証される。秘密情報を含む多様な提案の統合と市民の価値観に基づく判断により、政策の多面的な影響が包括的に評価され、政策の質と実効性が向上する。これらの効果により、ウィキッド・プロブレムに対する社会的な合意形成が促進され、実効性のある政策実施が可能となる。

\subsubsection{5.2 今後の課題}\label{ux4ecaux5f8cux306eux8ab2ux984c}

本研究が提案するシステムの社会実装には、技術的課題と制度的課題の両面において、さらなる研究開発が必要である。4.3節で述べた工学的アプローチにより、秘匿性と再現性に関する原理的な不安に対しては対応策の方向性が示されたが、残された課題は依然として多い。

技術的課題としては、第一に、TEEによる秘匿実行の実用性検証が必要である。TEE環境の構築コスト、モデル配布のインフラ整備、各事業者への導入支援体制など、実務的な課題が存在する。また、TEEにはサイドチャネル攻撃などの脆弱性が報告されており、セキュリティ面での継続的な監視と対策が求められる。第二に、決定論的運用の有効性検証が必要である。Temperature=0設定とSelf-Consistency手法の組み合わせが、実際に行政手続きの要件（公平性・一貫性）を満たすレベルの再現性を達成できるかは、実証実験による検証が不可欠である。第三に、市民討議プロセスの設計と実装が必要である。どのように討議を運営し、市民と研究者の対話を促進し、憲法的原則として文書化するかの具体的な方法論を確立する必要がある。第四に、Constitutional AI訓練による原則内在化の信頼性評価が必要である。市民討議で策定された原則がLLM訓練にどう変換されるか、その手続きの設計と、原則内在化の信頼性を評価する指標の開発が求められる。

制度的課題としては、第一に、地方自治体や政府機関との連携による実証実験が不可欠である。特定の政策分野（環境、福祉、都市計画等）において、小規模なパイロットプロジェクトを実施し、TEE環境での運用可能性と決定論的運用の有効性を含めて検証する必要がある。第二に、法的・制度的枠組みの整備が必要である。TEEによる秘匿実行の法的位置づけ、LLMによる評価結果の行政手続きにおける扱い、個人情報保護との関係などについて、法的検討が求められる。第三に、社会的受容性の調査と向上が重要である。市民や専門家がシステムをどのように認識し、どの程度信頼するかを調査し、必要に応じてシステム設計や説明方法を改善する必要がある。

さらに、長期的な研究課題として、AIの継続的な進化への対応がある。LLMやTEE技術は急速に発展しており、新しい手法や改良が継続的に提案されている。本システムも、これらの技術進化を取り込みながら、継続的に改善していく必要がある。特に、より安全なTEE実装の登場や、Constitutional AI訓練手法の発展に対応し、システムを更新していくことが重要である。

\subsubsection{5.3 今後の展望}\label{ux4ecaux5f8cux306eux5c55ux671b}

本研究が提案する政策対話インフラは、ウィキッド・プロブレムの政策評価という特定の応用領域から始まるが、その適用範囲は広範に及ぶ可能性がある。

短期的には、地方自治体レベルでの具体的な政策課題への適用が期待される。例えば、地域の環境政策、福祉政策、都市計画などにおいて、自治体が運営する市民討議を通じて評価原則を策定し、地域住民と研究機関が協働して政策を評価し、合意形成を図るプラットフォームとしての活用が考えられる。市民討議により地域固有の価値観が反映され、秘匿性の保証により研究機関が未公開の研究成果を政策評価に活用できるようになる。

中期的には、国レベルの重要政策の評価への展開が期待される。地球温暖化対策、少子高齢化対策、エネルギー政策など、国家的な重要課題において、全国規模の市民討議を通じて評価原則を策定し、多様なステークホルダーの専門知を統合し、科学的根拠に基づく政策評価を実現する。市民討議による原則策定とConstitutional AI訓練により、特定の政治的立場に偏らない公平な評価が可能となり、超党派的な政策合意の形成を支援できる。

長期的には、国際的な政策協調への応用も視野に入る。気候変動、感染症対策、サイバーセキュリティなど、グローバルな協調が必要な課題において、各国が保有する機密情報を秘匿しながら、国際的な政策評価と合意形成を行うプラットフォームとしての発展が期待される。ZK-SNARKsの秘匿性により、国家安全保障上の機密を保護しながら、科学的知見の共有が可能となる。

さらに、政策評価以外の分野への応用も考えられる。企業の戦略的意思決定、研究開発プロジェクトの評価、医療における診断支援など、専門知の統合と秘匿性が同時に要求される多様な領域において、本研究の枠組みは有用である。Constitutional AI訓練による倫理的制約の組み込みは、AI応用の信頼性を確保する一般的な手法として、広範な領域で活用される可能性がある。

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{6. 結論}\label{ux7d50ux8ad6}

本研究は、ウィキッド・プロブレムの政策評価における市民参加と専門的判断の両立という構造的課題を解決するため、市民討議による原則策定、ZK-SNARKsによる秘密情報の秘匿化、Constitutional AI訓練を統合した政策対話インフラを提案した。市民と研究者が討議を通じて憲法的原則を共同策定し、ZK-SNARKsが政策提案に含まれる秘密情報の秘匿化処理を担い、Constitutional AI訓練により市民の価値観と専門的価値観を埋め込んだLLM as a Judgeが秘密情報を含む提案の評価を実行する。この技術統合により、民主的正当性と専門的評価を両立させた。

提案システムの特徴は、市民討議、ZK-SNARKs、Constitutional AI訓練の役割分担にある。市民討議により憲法的原則に民主的正当性を付与し、ZK-SNARKsは政策提案に含まれる秘密情報の秘匿化処理を担当し、提案者の機密情報を保護しながらLLMの評価に使用できるようにする。Constitutional AI訓練手法により、市民討議で策定された憲法的原則と専門的価値観がLLMに内在化され、民主的に策定された制約と専門的判断基準の下で秘密情報を含む提案を自律的に評価することが可能となる。楕円曲線暗号がZK-SNARKsの数学的安全性を保証するように、市民討議とConstitutional AIがLLMの民主的正当性と専門性を保証する。

また、LLMとZK-SNARKsの本質的な違い（数学的保証と確率的期待）に対処するため、2つの工学的アプローチを提案した。TEE（Trusted Execution Environment）による分散型評価モデルでは、訓練済みLLMをコンテナ化して各事業者に配布し、秘密データをローカル環境から外に出さずに評価を実行する。Temperature=0設定とSelf-Consistency手法による決定論的運用では、LLMの確率的な揺らぎを抑制し、行政手続きに求められる再現性と一貫性を高める。これらはZK-SNARKsのような数学的保証を提供するものではないが、実用上の信頼性を高められる可能性がある。

本システムにより、市民参加による民主的正当性の確保、秘密情報を含む政策提案の実現、専門的評価、公平性確保、自治体・行政による説明責任向上を同時に達成し、奥田（2019）らが指摘する「ステークホルダーの合意調達と、柔軟かつ迅速な専門知・実践知の調達・適用」の連動を、秘密情報を保護しながら実現することを目指す。今後は、TEE環境での運用可能性の検証、決定論的運用の有効性実証、市民討議プロセスの設計、技術的実装の詳細設計、実証実験による有効性検証、法的・制度的課題の整理を通じて、真に実用的な政策対話インフラの社会実装を目指す。

\pandocbounded{\includesvg[keepaspectratio]{framework-objectives.svg}}
\emph{図9：提案する政策対話インフラの4つの目的}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{参考文献}\label{ux53c2ux8003ux6587ux732e}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Rittel, H. W., \& Webber, M. M. (1973). Dilemmas in a general theory of planning. \emph{Policy Sciences}, 4(2), 155-169.
\item
  奥田恒 (2019).「マイケル・ハウレットの『政策統合』アプローチ：ウィキッド・プロブレムへの対処戦略からの検討」『社会システム研究』22, 191-206. https://doi.org/10.14989/241035
\item
  Ben-Sasson, E., Chiesa, A., Tromer, E., \& Virza, M. (2014). Succinct non-interactive zero knowledge for a von Neumann architecture. \emph{Proceedings of the 23rd USENIX Security Symposium}, 781-796.
\item
  Groth, J. (2016). On the size of pairing-based non-interactive arguments. \emph{Advances in Cryptology -- EUROCRYPT 2016}. https://eprint.iacr.org/2016/260.pdf
\item
  Gu, J., Jiang, X., Shi, Z., Tan, H., Zhai, X., Xu, C., Li, W., Shen, Y., Ma, S., Liu, H., Wang, S., Zhang, K., Wang, Y., Gao, W., Ni, L., \& Guo, J. (2024). A survey on LLM-as-a-Judge. \emph{arXiv preprint} arXiv:2411.15594. https://doi.org/10.48550/arXiv.2411.15594
\item
  Li, H., Dong, Q., Chen, J., Su, H., Zhou, Y., Ai, Q., Ye, Z., \& Liu, Y. (2024). LLMs-as-Judges: A comprehensive survey on LLM-based evaluation methods. \emph{arXiv preprint} arXiv:2412.05579. https://arxiv.org/abs/2412.05579
\item
  Zheng, L., Chiang, W. L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E. P., Zhang, H., Gonzalez, J. E., \& Stoica, I. (2023). Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. \emph{Advances in Neural Information Processing Systems}, 36.
\item
  Bai, Y., Jones, A., et al.~(2022). Constitutional AI: Harmlessness from AI feedback. \emph{arXiv preprint} arXiv:2212.08073. https://arxiv.org/abs/2212.08073
\item
  Saha, S., et al.~(2025). Learning to plan \& reason for evaluation with Thinking-LLM-as-a-Judge. \emph{arXiv:2501.18099v1}.
\item
  Buterin, V. (2022). How do trusted setups work? \emph{Vitalik Buterin's website}. https://vitalik.eth.limo/general/2022/03/14/trustedsetup.html
\item
  Ethereum Foundation. (2023). KZG Ceremony. https://ceremony.ethereum.org/
\item
  Bünz, B., Fisch, B., \& Szepieniec, A. (2022). Powers-of-Tau to the People: Decentralizing Setup Ceremonies. \emph{Cryptology ePrint Archive}, Paper 2022/1592. https://eprint.iacr.org/2022/1592
\item
  杉谷和哉 (2019).『政策にエビデンスは必要なのか：EBPMと政治のあいだ』ミネルヴァ書房.
\item
  窪田好男・山谷清志 編 (2020).『政策評価の実践とその課題：アカウンタビリティのジレンマ』晃洋書房.
\item
  Argyrous, G. (2012). Evidence Based Policy: Principles of Transparency and Accountability. \emph{Australian Journal of Public Administration}, 71(4), 457--468. https://doi.org/10.1111/j.1467-8500.2012.00786.x
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{付録：数式表記の補足説明}

\textbf{A.1 ZK-SNARKsにおける楕円曲線ペアリング}

楕円曲線\(E\)上の2つの群\(\mathbb{G}_1, \mathbb{G}_2\)と、ペアリング関数\(e: \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T\)により、効率的な証明生成と検証が実現される。証明\(\pi\)の検証は、\(e(A, B) = e(C, D)\)の形式の等式検証に帰着される。
